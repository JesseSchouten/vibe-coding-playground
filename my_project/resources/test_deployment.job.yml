resources:
  jobs:
    test_notebook_job:
      name: test_notebook_job
      
      # Job schedule - runs daily at 8 AM UTC
      schedule:
        quartz_cron_expression: "0 0 8 * * ?"
        timezone_id: "UTC"
        pause_status: UNPAUSED
      
      # Email notifications on job success/failure
      email_notifications:
        on_success:
          - ${workspace.current_user.userName}
        on_failure:
          - ${workspace.current_user.userName}
      
      # Timeout settings
      timeout_seconds: 3600
      max_concurrent_runs: 1
      
      tasks:
        - task_key: run_test_notebook
          
          # Notebook configuration
          notebook_task:
            notebook_path: ../notebooks/test_notebook.py
            base_parameters:
              environment: ${bundle.target}
          
          # Compute configuration - using serverless
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "i3.xlarge"
            num_workers: 1
            spark_conf:
              "spark.databricks.cluster.profile": "serverless"
            custom_tags:
              project: "my_project"
              environment: ${bundle.target}
          
          # Timeout for this specific task
          timeout_seconds: 1800
          
          # Retry configuration
          max_retries: 2
          min_retry_interval_millis: 60000
          retry_on_timeout: true
